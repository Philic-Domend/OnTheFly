'''
Dataloader for rollout datasets generated by pi0. 

pi0 is from the following repo:
https://github.com/Physical-Intelligence/openpi
'''

from collections import defaultdict
import glob
import pickle
from pathlib import Path

import cv2
import imageio
import natsort
import numpy as np
import pandas as pd
import torch
from tqdm import tqdm

from failure_prob.conf import Config
from .utils import Rollout, set_task_min_step, split_rollouts_by_seen_unseen, process_tensor_idx_rel

from .openvla import split_rollouts as split_rollouts_openvla
from .pizero_fast import compute_hand_crafted_metrics

import json
import os
from typing import List, Dict, Any


def load_rollouts_from_root(load_root: Path, cfg: Config, success_labels: np.ndarray = None) -> list[Rollout]:
    '''
    actions <class 'numpy.ndarray'> (50, 7) float64
    pre_velocity <class 'numpy.ndarray'> (10, 50, 1024) float32
    raw_actions <class 'numpy.ndarray'> (50, 32) float32
    state <class 'numpy.ndarray'> (32,) float32
    '''
    env_records_folder = load_root / "env_records"
    policy_records_folder = load_root / "policy_records"
    
    assert env_records_folder.exists(), f"Path {env_records_folder} does not exist"
    assert policy_records_folder.exists(), f"Path {policy_records_folder} does not exist"
    
    env_record_paths = glob.glob(str(env_records_folder / "*.pkl"))
    policy_record_paths = glob.glob(str(policy_records_folder / "*meta.pkl"))
    
    assert len(env_record_paths) > 0, f"No env records found in {env_records_folder}"
    assert len(policy_record_paths) > 0, f"No policy records found in {policy_records_folder}"
    
    env_record_paths = natsort.natsorted(env_record_paths)
    policy_record_paths = natsort.natsorted(policy_record_paths)
    
    all_rollouts = []
    
    policy_step = 0

    for env_record_path in tqdm(env_record_paths):
        # Load the meta data from the env record
        env_record = pickle.load(open(env_record_path, "rb"))
        mp4_path = env_record_path.replace(".pkl", ".mp4")
        
        # Load hidden features from corresponding policy records
        model_infer_times = env_record["model_infer_times"]
        policy_records = []
        for i in range(model_infer_times):
            policy_record_path = policy_record_paths[policy_step]
            policy_records.append(pickle.load(open(policy_record_path, "rb")))
            policy_step += 1
            
        # Extract hidden states and actions from policy records
        hidden_states = []
        action_vectors = []
        for policy_record in policy_records:
            # hidden_state shape: (n_diff_steps, n_pred_horizon, dim_feats)
            hidden_state = policy_record[cfg.dataset.feat_name]
            
            # handle the pred_horizon dimension
            # (n_diff_steps, n_pred_horizon, dim_feats) -> (n_diff_steps, dim_feats)
            hidden_state = process_tensor_idx_rel(hidden_state, cfg.dataset.horizon_idx_rel)
            
            # handle the diff_steps dimension
            # (n_diff_steps, dim_feats) -> (dim_feats)
            hidden_state = process_tensor_idx_rel(hidden_state, cfg.dataset.diff_idx_rel)
            
            hidden_states.append(hidden_state)
            
            pred_horizon = policy_record["actions"].shape[0]
            dim_action = policy_record["actions"].shape[1]
            action = policy_record["actions"].reshape(-1) # (pred_horizon*action_dim)
            action_vectors.append(action)
            
        hidden_states = np.stack(hidden_states, axis=0).astype(np.float32)
        hidden_states = torch.from_numpy(hidden_states) # (n_steps, hidden_dim)
        action_vectors = np.stack(action_vectors, axis=0).astype(np.float32)
        action_vectors = torch.from_numpy(action_vectors) # (n_steps, pred_horizon*action_dim)

        cfg.dataset.dim_features = hidden_states.shape[-1]
        cfg.dataset.dim_action = dim_action
        cfg.dataset.pred_horizon = pred_horizon
        cfg.dataset.exec_horizon = env_record['replan_steps']
        
        # Compute hand-crafted metrics
        hand_crafted_metrics = None
        if cfg.train.log_precomputed or cfg.train.log_precomputed_only:
            hand_crafted_metrics = compute_hand_crafted_metrics(
                cfg=cfg,
                policy_records=policy_records,
                exec_horizon=env_record['replan_steps'],
            )
        
        rollout = Rollout(
            task_name=None,
            vl_states=None,
            hidden_states=hidden_states,
            task_suite_name=env_record["task_suite_name"],
            task_id=env_record["task_id"],
            task_description=env_record["task_description"],
            episode_idx=env_record["episode_idx"],
            episode_success=env_record["episode_success"],
            mp4_path=mp4_path,
            logs=hand_crafted_metrics,
            exec_horizon=env_record['replan_steps'],
            action_vectors=action_vectors,
            step_labels=None  # 先设置为 None
        )

        if success_labels is None:
            print("1111111111111111")

        # 如果有提供 success_labels，添加时间步级标签
        if success_labels is not None:
            task_id = rollout.task_id
            episode_idx = rollout.episode_idx
            
            # 检查索引是否在有效范围内
            if (task_id < success_labels.shape[0] and 
                episode_idx < success_labels.shape[1]):
                
                # 获取该 rollout 的标签
                labels = success_labels[task_id, episode_idx]
                
                # 去掉填充值 (-1)，只保留有效标签
                valid_labels = labels[labels != -1]
                
                if len(valid_labels) > 0:
                    # 转换为 torch tensor
                    step_labels = torch.from_numpy(valid_labels).float()
                    
                    # 检查标签长度是否与隐藏状态长度匹配
                    if len(step_labels) == rollout.hidden_states.shape[0]:
                        rollout.step_labels = step_labels
                    else:
                        # 如果不匹配，尝试截断或填充
                        n_pred_steps = rollout.hidden_states.shape[0]
                        if len(step_labels) > n_pred_steps:
                            rollout.step_labels = step_labels[:n_pred_steps]
                        else:
                            # 填充
                            padded = torch.zeros(n_pred_steps)
                            padded[:len(step_labels)] = step_labels
                            if len(step_labels) > 0:
                                padded[len(step_labels):] = step_labels[-1]
                            rollout.step_labels = padded

        all_rollouts.append(rollout)

        '''
        # 完整输出所有信息
        print(f"\ntask{rollout.task_id}_episode{rollout.episode_idx}:")
        print(f"  hidden_states: shape {list(rollout.hidden_states.shape)}")
        print(f"  action_vectors: shape {list(rollout.action_vectors.shape)}")
        print(f"  episode_success: {rollout.episode_success}")
        print(f"  exec_horizon: {rollout.exec_horizon}")
        
        # 完整输出 step_labels 的所有值
        if rollout.step_labels is not None:
            print(f"  step_labels: shape {list(rollout.step_labels.shape)}")
            print(f"  step_labels values: {rollout.step_labels.tolist()}")
        else:
            print(f"  step_labels: None")
        
        print("-" * 80)
        '''

    print("policy_steps num:")
    print(policy_step)
    
    all_rollouts = set_task_min_step(all_rollouts)
    
    return all_rollouts


def load_rollouts(cfg: Config, success_labels: np.ndarray = None) -> list[Rollout]:
    load_root = Path(cfg.dataset.data_path)
    all_rollouts = load_rollouts_from_root(load_root, cfg, success_labels)

    if cfg.dataset.data_path_unseen is not None:
        seen_rollouts = all_rollouts
        seen_task_ids = set([r.task_id for r in seen_rollouts])
        n_seen_tasks = len(seen_task_ids)
        print(f"Seen tasks: {seen_task_ids}")
        print(f"Number of seen tasks: {n_seen_tasks}")
        
        unseen_root = Path(cfg.dataset.data_path_unseen)
        unseen_rollouts = load_rollouts_from_root(unseen_root, cfg)
        
        for r in unseen_rollouts:
            r.task_id = r.task_id + n_seen_tasks

        unseen_task_ids = set([r.task_id for r in unseen_rollouts])
        n_unseen_tasks = len(unseen_task_ids)
        print(f"Unseen tasks: {unseen_task_ids}")
        print(f"Number of unseen tasks: {n_unseen_tasks}")
        
        # Overwrite the unseen_task_ratio in the config
        cfg.dataset.unseen_task_ratio = n_unseen_tasks / (n_seen_tasks + n_unseen_tasks)
        print(f"Overwrite unseen_task_ratio: {cfg.dataset.unseen_task_ratio}")
        
        all_rollouts = seen_rollouts + unseen_rollouts
    
    return all_rollouts


def split_rollouts(cfg: Config, all_rollouts: list[Rollout]) -> tuple[list[Rollout], list[Rollout]]:
    if cfg.dataset.data_path_unseen is None:
        rollouts_by_split_name = split_rollouts_openvla(cfg, all_rollouts)
    else:
        task_ids = list(set([r.task_id for r in all_rollouts]))
        task_ids = sorted(task_ids)
        n_unseen = round(cfg.dataset.unseen_task_ratio * len(task_ids))
        n_seen = len(task_ids) - n_unseen
        seen_task_ids = task_ids[:n_seen]
        unseen_task_ids = task_ids[n_seen:]
        
        rollouts_by_split_name = split_rollouts_by_seen_unseen(
            cfg, all_rollouts, seen_task_ids, unseen_task_ids
        )
        
    return rollouts_by_split_name


def split_rollouts_plus(cfg: Config, all_rollouts) -> dict[str, list[Rollout]]:

    np.random.seed(cfg.train.seed)
    torch.manual_seed(cfg.train.seed)

    # 1. 先划分train/val组合（完整组合）
    task_combos = sorted({(r.task_name, r.task_id) for r in all_rollouts})
    np.random.shuffle(task_combos)

    print(task_combos)
    
    n_unseen = round(cfg.dataset.unseen_task_ratio * len(task_combos))
    seen_combos = task_combos[n_unseen:]
    unseen_combos = task_combos[:n_unseen]
    
    # 2. 在val内部划分seen/unseen轨迹（按比例）
    val_unseen_rollouts = [r for r in all_rollouts if (r.task_name, r.task_id) in unseen_combos]
    
    # 按组合分组val轨迹
    train_rollouts = []
    val_seen_rollouts = []

    for task_name, task_id in seen_combos:
        combo_rollouts = [r for r in all_rollouts 
                        if r.task_name == task_name and r.task_id == task_id]
        if combo_rollouts:
            n_train = round(cfg.dataset.seen_train_ratio * len(combo_rollouts))
            permuted = torch.randperm(len(combo_rollouts))
            train_rollouts.extend([combo_rollouts[i] for i in permuted[:n_train]])
            val_seen_rollouts.extend([combo_rollouts[i] for i in permuted[n_train:]])
    
    # 构建结果
    result = {"train": train_rollouts, "val_seen": val_seen_rollouts, "val_unseen": val_unseen_rollouts}
    result = {k: v for k, v in result.items() if v}
    
    # 打印统计信息
    print(f"\n任务组合总数: {len(task_combos)}")
    print(f"Seen组合: {len(seen_combos)}个, Unseen组合: {len(unseen_combos)}个")
    
    for split_name, rollouts in result.items():
        print(f"\n=== {split_name.upper()} ===")
        if not rollouts: 
            print("  无数据")
            continue
        
        # 按组合统计
        from collections import defaultdict
        combo_stats = defaultdict(list)
        for r in rollouts:
            combo_stats[(r.task_name, r.task_id)].append(r)
        
        print(f"  包含 {len(combo_stats)} 个任务组合:")
        for (name, tid), rollout_list in combo_stats.items():
            n_success = sum(r.episode_success for r in rollout_list)
            print(f"    ({name}, {tid}): {len(rollout_list)}条, {n_success}成功")
        
        # 总体统计
        total_success = sum(r.episode_success for r in rollouts)
        print(f"  总计: {len(rollouts)}条轨迹, {total_success}成功")
        
        # 打印3条轨迹的详细信息
        print(f"\n  前3条轨迹详情:")
        for i, r in enumerate(rollouts[:3]):
            print(f"\n  轨迹{i} ({r.task_name}, {r.task_id}):")
            for attr in dir(r):
                if not attr.startswith('_'):
                    try:
                        val = getattr(r, attr)
                        if not callable(val):
                            # 打印属性值和形状
                            if hasattr(val, 'shape'):
                                print(f"    {attr}: shape={val.shape}, values={repr(val)[:80]}...")
                            elif hasattr(val, '__len__'):
                                print(f"    {attr}: length={len(val)}, values={repr(val)[:80]}...")
                            else:
                                print(f"    {attr}: {val}")
                    except:
                        continue

        # 生成分割结果文件
        with open("/data/huangdi/huangruixiang/SAFE/SAFE/rollout_split.txt", "w") as f:
            for split_name, rollouts in result.items():
                f.write(f"{split_name}:\n")
                for i, r in enumerate(rollouts):
                    f.write(f"rollout{i}: {r.task_name}-task{r.task_id}-episode{r.episode_idx}\n")
                f.write("\n")
        
        print("分割结果已保存到 rollout_split.txt")
    
    return result


def load_rollouts_plus(
    load_root: List[Path], 
    cfg: Config, 
    success_labels: List[Dict[str, Any]] = None,
    task_names: List[str] = None
) -> List[Rollout]:
    
    print(f"Load roots: {load_root}")
    
    all_rollouts = load_rollouts_from_root_plus(load_root, cfg, success_labels, task_names)
    
    return all_rollouts


from typing import List, Dict, Any

def load_rollouts_from_root_plus(
    load_root: List[Path], 
    cfg: Config, 
    success_labels: List[Dict[str, Any]] = None,
    task_names: List[str] = None
) -> List[Rollout]:
    '''
    actions <class 'numpy.ndarray'> (50, 7) float64
    pre_velocity <class 'numpy.ndarray'> (10, 50, 1024) float32
    raw_actions <class 'numpy.ndarray'> (50, 32) float32
    state <class 'numpy.ndarray'> (32,) float32
    '''

    load_root = [Path(root) if isinstance(root, str) else root for root in load_root]

    # print(load_root)

    all_rollouts = []

    for root in load_root:
        task_name = None
        for name in task_names:
            if name in str(root):
                task_name = name
                break

        current_batch = []  # 新增：记录当前批次的rollouts

        env_records_folder = root / "env_records"
        policy_records_folder = root / "policy_records"

        print(env_records_folder)
    
        assert env_records_folder.exists(), f"Path {env_records_folder} does not exist"
        assert policy_records_folder.exists(), f"Path {policy_records_folder} does not exist"
    
        env_record_paths = glob.glob(str(env_records_folder / "task*.pkl"))
        policy_record_paths = glob.glob(str(policy_records_folder / "*meta.pkl"))
    
        assert len(env_record_paths) > 0, f"No env records found in {env_records_folder}"
        assert len(policy_record_paths) > 0, f"No policy records found in {policy_records_folder}"
    
        env_record_paths = natsort.natsorted(env_record_paths)
        policy_record_paths = natsort.natsorted(policy_record_paths)
    
        policy_step = 0

        for env_record_path in tqdm(env_record_paths):
            # Load the meta data from the env record
            env_record = pickle.load(open(env_record_path, "rb"))
            mp4_path = env_record_path.replace(".pkl", ".mp4")
            
            # Load hidden features from corresponding policy records
            model_infer_times = env_record["model_infer_times"]
            policy_records = []
            for i in range(model_infer_times):
                policy_record_path = policy_record_paths[policy_step]
                policy_records.append(pickle.load(open(policy_record_path, "rb")))
                policy_step += 1
                
            # Extract hidden states and actions from policy records
            vl_states = []
            hidden_states = []
            action_vectors = []
            
            for policy_record in policy_records:

                # 新增！
                vl_states.append(policy_record["vl_states"][-1])

                # hidden_state shape: (n_diff_steps, n_pred_horizon, dim_feats)
                hidden_state = policy_record[cfg.dataset.feat_name]
                
                # handle the pred_horizon dimension
                # (n_diff_steps, n_pred_horizon, dim_feats) -> (n_diff_steps, dim_feats)
                hidden_state = process_tensor_idx_rel(hidden_state, cfg.dataset.horizon_idx_rel)
                
                # handle the diff_steps dimension
                # (n_diff_steps, dim_feats) -> (dim_feats)
                hidden_state = process_tensor_idx_rel(hidden_state, cfg.dataset.diff_idx_rel)
                
                hidden_states.append(hidden_state)
                
                pred_horizon = policy_record["actions"].shape[0]
                dim_action = policy_record["actions"].shape[1]
                action = policy_record["actions"].reshape(-1) # (pred_horizon*action_dim)
                action_vectors.append(action)
                
            vl_states = np.stack(vl_states, axis=0).astype(np.float32)
            vl_states = torch.from_numpy(vl_states) # (n_steps, 2048)
            hidden_states = np.stack(hidden_states, axis=0).astype(np.float32)
            hidden_states = torch.from_numpy(hidden_states) # (n_steps, hidden_dim)
            action_vectors = np.stack(action_vectors, axis=0).astype(np.float32)
            action_vectors = torch.from_numpy(action_vectors) # (n_steps, pred_horizon*action_dim)

            cfg.dataset.dim_features = hidden_states.shape[-1]
            cfg.dataset.dim_action = dim_action
            cfg.dataset.pred_horizon = pred_horizon
            cfg.dataset.exec_horizon = env_record['replan_steps']
            
            # Compute hand-crafted metrics
            hand_crafted_metrics = None
            if cfg.train.log_precomputed or cfg.train.log_precomputed_only:
                hand_crafted_metrics = compute_hand_crafted_metrics(
                    cfg=cfg,
                    policy_records=policy_records,
                    exec_horizon=env_record['replan_steps'],
                )
            
            rollout = Rollout(
                task_name=task_name,
                vl_states=vl_states,
                hidden_states=hidden_states,
                task_suite_name=env_record["task_suite_name"],
                task_id=env_record["task_id"],
                task_description=env_record["task_description"],
                episode_idx=env_record["episode_idx"],
                episode_success=env_record["episode_success"],
                mp4_path=mp4_path,
                logs=hand_crafted_metrics,
                exec_horizon=env_record['replan_steps'],
                action_vectors=action_vectors,
                step_labels=None  # 先设置为 None
            )

            if success_labels is None:
                print("1111111111111111")

            # 如果有提供 success_labels，添加时间步级标签
            if success_labels is not None:
                matched_labels = [label for label in success_labels 
                                if label['task_id'] == rollout.task_id 
                                and label['episode_id'] == rollout.episode_idx
                                and label['task_name'] == rollout.task_name]
                if matched_labels:
                    label = matched_labels[0]
                    rollout.step_labels = torch.tensor(label['frame_scores'], dtype=torch.float32)

            all_rollouts.append(rollout)
            current_batch.append(rollout)  # 添加到当前批次

        if task_name and current_batch:
            save_path = f"/data/huangdi/huangruixiang/SAFE/SAFE/{task_name}_rollouts.pkl"
            with open(save_path, 'wb') as f:
                pickle.dump(current_batch, f)
            print(f"已保存 {len(current_batch)} 个rollouts到 {save_path}")

        '''
        # 完整输出所有信息
        print(f"\ntask{rollout.task_id}_episode{rollout.episode_idx}:")
        print(f"  hidden_states: shape {list(rollout.hidden_states.shape)}")
        print(f"  action_vectors: shape {list(rollout.action_vectors.shape)}")
        print(f"  episode_success: {rollout.episode_success}")
        print(f"  exec_horizon: {rollout.exec_horizon}")
        
        # 完整输出 step_labels 的所有值
        if rollout.step_labels is not None:
            print(f"  step_labels: shape {list(rollout.step_labels.shape)}")
            print(f"  step_labels values: {rollout.step_labels.tolist()}")
        else:
            print(f"  step_labels: None")
        
        print("-" * 80)
        '''

        print("policy_steps num:")
        print(policy_step)

    def save_rollouts_info(all_rollouts, save_path="/data/huangdi/huangruixiang/SAFE/SAFE/plus_all_rollouts.txt"):
        """保存rollouts信息到文件"""
        with open(save_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("ROLLOUTS 详细信息\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"总计: {len(all_rollouts)} 个rollouts\n\n")
            
            # 按任务统计
            task_stats = {}
            for rollout in all_rollouts:
                task = getattr(rollout, 'task_name', 'unknown')
                task_stats[task] = task_stats.get(task, 0) + 1
            
            f.write("按任务统计:\n")
            for task, count in task_stats.items():
                f.write(f"  {task}: {count}个\n")
            f.write("\n")
            
            # 详细记录每个rollout
            for i, rollout in enumerate(all_rollouts):
                f.write(f"[Rollout {i}]\n")
                f.write(f"  任务名称: {getattr(rollout, 'task_name', 'N/A')}\n")
                f.write(f"  task_suite_name: {rollout.task_suite_name}\n")
                f.write(f"  task_id: {rollout.task_id}\n")
                f.write(f"  episode_idx: {rollout.episode_idx}\n")
                f.write(f"  任务描述: {rollout.task_description}\n")
                f.write(f"  是否成功: {rollout.episode_success}\n")
                f.write(f"  mp4路径: {rollout.mp4_path}\n")
                f.write(f"  exec_horizon: {rollout.exec_horizon}\n")
                
                # 记录形状信息
                f.write(f"  vl_states形状: {rollout.vl_states.shape if rollout.vl_states is not None else 'None'}\n")
                f.write(f"  hidden_states形状: {rollout.hidden_states.shape if rollout.hidden_states is not None else 'None'}\n")
                f.write(f"  action_vectors形状: {rollout.action_vectors.shape if rollout.action_vectors is not None else 'None'}\n")
                f.write(f"  step_labels形状: {rollout.step_labels.shape if rollout.step_labels is not None else 'None'}\n")
                
                # 记录step_labels的前几个值（如果存在）
                if rollout.step_labels is not None and len(rollout.step_labels) > 0:
                    f.write(f"  step_labels前5个值: {rollout.step_labels[:5].tolist()}\n")
                    f.write(f"  step_labels后5个值: {rollout.step_labels[-5:].tolist()}\n")
                    f.write(f"  step_labels平均值: {rollout.step_labels.mean().item():.4f}\n")
                    f.write(f"  step_labels标准差: {rollout.step_labels.std().item():.4f}\n")
                
                f.write("-" * 60 + "\n")
        
        print(f"Rollouts信息已保存到: {save_path}")
    
    save_rollouts_info(all_rollouts)

    # 最后也可以保存全部rollouts
    with open("/data/huangdi/huangruixiang/SAFE/SAFE/all_rollouts.pkl", 'wb') as f:
        pickle.dump(all_rollouts, f)
    
    print(f"总共保存了 {len(all_rollouts)} 个rollouts")

    return all_rollouts